{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle_report : \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "The udacity project was divided into three main parts :<br>\n",
    " - Gathering \n",
    " - Accessing \n",
    " - Cleaning \n",
    " <br> \n",
    " \n",
    "## Gathering : \n",
    "\n",
    "\n",
    "<br> \n",
    " - First of all the pandas , requests and tweepy  libraries were imported . \n",
    " - Next the twitter-archive-enchanced.csv file which was provided to us before hand was read into the pandas dataframe 'df1'. \n",
    " - Next the image prediction data was loaded from the internet using the url of the data and written into a file \"image_predictions.tsv\" on our machine .This is a tab seperated file \n",
    " - The data from this file is fed to a pandas datafram 'df2'.\n",
    " - Finally using tweepy library which is open-sourced, hosted on GitHub and enables Python to communicate with Twitter platform and use its API the additional data about tweet ids of data already present in our dataframe df1 was read . This required generating a consumer key , consumer secret , access token and access secret from twitter to access its API. \n",
    " - The data was returned in json format and written into a file \"tweet_json.txt\" using the json.dump function . The data from this file was read into a dataframe twitter and it had 32 columns from which we took only 5 columns and constituted a new dataframe df3 .\n",
    " - Now we have 3 dataframes df1,df2 and df3 respectively .\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing : \n",
    "<br> \n",
    " ### df1 : <br> \n",
    "  \n",
    " - Using the info function for df1 it was found that some tweets didn't have a url , while many columns had erronous datatypes . \n",
    " - using the value_counts function on name it was found that many dogs had name such as a , an , the , quite , none . \n",
    " - No tweet ids were repeated . \n",
    " - Some data had invalid denominator rating which was not equal to 10 . \n",
    " - No numerator rating was Nan . \n",
    "  <br> \n",
    "  \n",
    "### df2 : <br>\n",
    " - Tweet_id was int type whereas it should be a string . \n",
    " - I tried to find out if any url had been duplicated but none of them were duplicates . \n",
    " <br>\n",
    "### df3 : <br>\n",
    "  - The column here is id whereas in other two tables it is tweet_id and should be a string instead of int .\n",
    "  - None of the twitter ids were duplicated . \n",
    "  - None of the retweeted counts or favorite counts were Nan . \n",
    "  - Most of the tweets were in english text and 8 other language tags 'und' , 'nl' , 'in' , 'es' , 'et' , 'ro' , 'eu' , 'tl ' were present which were undescriptive . \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning : \n",
    "\n",
    " ### Quality issues :\n",
    "#### In the dataframe from twitter archive (df1):\n",
    " - some have missing urls.\n",
    " - tweet id  , in_ reply_to_status_id , in_reply_to_user_id , retweeted_status_id, retweeted_status_user_id have erronous data type . \n",
    " - missing names such as a , an , none , the\n",
    " - invalid denominator rating .\n",
    " - remove retweeted stuff from dataframe <br>\n",
    " \n",
    " \n",
    "#### In dataframe from the image_preditictions.tsv file (df2):\n",
    " - The tweet_id erronous datatype . \n",
    " \n",
    "\n",
    "\n",
    "\n",
    "#### In dataframe from twitter API (df3):\n",
    " - id is tweet_id in all otherdata sets except this one and has errornous data type.\n",
    " - undescriptive language tags .\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "### Tideness issues :\n",
    " - doggo, floofer , pupper have missing values could be melted into one in df1 . \n",
    " - All data frames combined to form master dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps followed for cleaning  :\n",
    "\n",
    " - First of all the copies of the dataframes were created . df1_c , df2_c and df3_c respectively . \n",
    " - Next all the rows whose url was not present in the copy of  dataframe df1 were removed . \n",
    " - The the datatype of tweet id  , in_ reply_to_status_id , in_reply_to_user_id , retweeted_status_id, retweeted_status_user_id was changed to object using astype function. \n",
    " - Then all the invalid names of dogs such as a ,an , the , quite were changed to 'none' using the replace function \n",
    " - Finally the invalid denominators were corrected to 10 . \n",
    " - Next all the tweets which were retweets to ids were removed from the dataframe .\n",
    " - The datatype of ids in both copies of df2 and df3 changed to object . \n",
    " - The name of id in df3 changed to tweet_id for ease of merging using replace function . \n",
    " - All the languages which were not english replaced with 'not english' tag in copy of df3 . \n",
    " - A new column called growth stage introduced in copy of df1 by extracting the stage from the tweet text . The columns doggo , floffer, pupper, puppo are dropped . \n",
    " - Finally the dataset df1_c and df2_c are merged using inner join and using the tweet_id intp dataframe master. \n",
    " - Then dataframe master and df3_c are merged together similarly to form a final dataframe final . \n",
    " - This dataframe is saved into a csv file called 'final.csv' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
